{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jupyter-dash"
      ],
      "metadata": {
        "id": "4-w3OJh5onwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from jupyter_dash import JupyterDash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output# Load Data"
      ],
      "metadata": {
        "id": "UOYbZ055owD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jvEfsMEoo2gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#webpage"
      ],
      "metadata": {
        "id": "mKSZdO3t6Qx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Google Drive"
      ],
      "metadata": {
        "id": "X1Zum9qM6WpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Connectiong to the Google Drive for the permanent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9rze4z0EW6pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the correct version of tensorflow in installed or not \n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "KAaGKC_TDwKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UgxzhmJwDfqM"
      },
      "outputs": [],
      "source": [
        "from numpy.random import seed\n",
        "seed(786)\n",
        "# Tensor flow for the fast calculation or computation\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(786)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CRCrwduIDfqP"
      },
      "outputs": [],
      "source": [
        "# Other imports like os for directory management and numpy for mathematical operation on arrays\n",
        "import os\n",
        "\n",
        "# Numpy for performing mathematical operations on arrays\n",
        "import numpy as np\n",
        "\n",
        "# Importing pandas for data visualization in the forms of tables or data frames\n",
        "import pandas as pd\n",
        "\n",
        "# Time for dealing with real time and the pillow for dealing with the image for predictions\n",
        "from time import strftime\n",
        "\n",
        "# Pillow for the image used for prediction\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t5POZ9v9DfqS"
      },
      "outputs": [],
      "source": [
        "# Loading all the files from the directory into variables\n",
        "X_TRAINING_PATH =  '/content/drive/MyDrive/MNIST/digit_xtrain.csv'\n",
        "X_TESTING_PATH =   '/content/drive/MyDrive/MNIST/digit_xtest.csv'\n",
        "Y_TRAINING_PATH =  '/content/drive/MyDrive/MNIST/digit_ytrain.csv'\n",
        "Y_TESTING_PATH =   '/content/drive/MyDrive/MNIST/digit_ytest.csv'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XJmYzsZDfqT"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Geting the wall time required for reading the y-training csv file\n",
        "y_training_all = np.loadtxt(Y_TRAINING_PATH, delimiter=',', dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlg_ZdMNDfqV"
      },
      "outputs": [],
      "source": [
        "y_training_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KL1me9ukDfqW"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_testing = np.loadtxt(Y_TESTING_PATH, delimiter=',', dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wGnvtWRDfqX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "x_training_all = np.loadtxt(X_TRAINING_PATH, delimiter=',', dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrRCUgNIDfqY"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "x_testing = np.loadtxt(X_TESTING_PATH, delimiter=',', dtype=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkK_qw6zDfqZ"
      },
      "source": [
        "# Visualizing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNUY9woKDfqa"
      },
      "outputs": [],
      "source": [
        "x_training_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX-AtzGSDfqb"
      },
      "outputs": [],
      "source": [
        "x_training_all[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oX9j1GoXDfqb"
      },
      "outputs": [],
      "source": [
        "y_training_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnPzy2YsDfqc"
      },
      "outputs": [],
      "source": [
        "x_testing.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUF8pKuwDfqc"
      },
      "outputs": [],
      "source": [
        "# First 10 labels from training dataset\n",
        "y_training_all[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "S3-LwrqnDfqd"
      },
      "outputs": [],
      "source": [
        "# Our Features are between 0 and 255 which is a large range. So, we have to rescale our training and testing dataset\n",
        "# After rescaling our data is between 0 and 1\n",
        "x_training_all = x_training_all / 255.0\n",
        "x_testing      =  x_testing / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_training_all[0]"
      ],
      "metadata": {
        "id": "P4wP4Qt5L_l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Our labels are 10 in total from 0 to 9\n",
        "NR_CLASSES = 10"
      ],
      "metadata": {
        "id": "CzQbr74OSoyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Rw6R_MlADfqg"
      },
      "outputs": [],
      "source": [
        "y_training_all = np.eye(NR_CLASSES)[y_training_all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE3E3ESVDfqg"
      },
      "outputs": [],
      "source": [
        "y_training_all.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfZMrDT3Dfqg"
      },
      "outputs": [],
      "source": [
        "y_testing = np.eye(NR_CLASSES)[y_testing]\n",
        "y_testing.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOGGING_PATH = '/content/sample_data/MNISTtensorboard_mnist_digit_logs/'\n",
        "\n",
        "VALIDATION_SIZE = 10000\n",
        "IMAGE_WIDTH = 28\n",
        "IMAGE_HEIGHT = 28\n",
        "CHANNELS = 1\n",
        "# Total number of features\n",
        "TOTAL_INPUTS = IMAGE_WIDTH*IMAGE_HEIGHT*CHANNELS "
      ],
      "metadata": {
        "id": "hguGPsTkGWv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have to divide our training dataset into smaller training and validation dataset\n",
        "# Training dataset contains 50000 and avalidation contains 10000"
      ],
      "metadata": {
        "id": "-fbNNPKlUcPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Wo4GWo5uDfqg"
      },
      "outputs": [],
      "source": [
        "# From start to the validation size\n",
        "x_val = x_training_all[:VALIDATION_SIZE]\n",
        "y_val = y_training_all[:VALIDATION_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val.shape"
      ],
      "metadata": {
        "id": "fw2f-bsHVB7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EwiwRaZNDfqi"
      },
      "outputs": [],
      "source": [
        "# From validation size till the end\n",
        "x_training = x_training_all[VALIDATION_SIZE:]\n",
        "y_training = y_training_all[VALIDATION_SIZE:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-m3BNKuDfqi"
      },
      "outputs": [],
      "source": [
        "x_training.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VnpOMUVnDfqj"
      },
      "outputs": [],
      "source": [
        "# Creating tensors\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# tf.placeholder is used for creating tensors 2 parameters (datatype, shape of tensor)\n",
        "X = tf.placeholder(tf.float32, shape=[None, TOTAL_INPUTS], name='X')\n",
        "Y = tf.placeholder(tf.float32, shape=[None, NR_CLASSES], name='labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qIsdT7A1Dfqj"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "# nr_epochs = 25\n",
        "# learning_rate = 1e-3\n",
        "nr_epochs = 50\n",
        "learning_rate = 1e-3\n",
        "\n",
        "n_hidden1 = 512\n",
        "n_hidden2 = 64"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1e-3"
      ],
      "metadata": {
        "id": "pxUuOYnPY5Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "D6EOIYC9Dfqj"
      },
      "outputs": [],
      "source": [
        "def setup_layer(input, weight_dim, bias_dim, name):\n",
        "    \n",
        "    with tf.name_scope(name):\n",
        "      \"\"\"\n",
        "      Iniatializing the weights\n",
        "      tf.truncated_normal generates random values execpt for extreme values \n",
        "      Shape = no of inputs and neurons in the layer\n",
        "      Standard Deviation tells how far appart weights should from each others\n",
        "      \"\"\"\n",
        "      initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
        "      # Calculations for weights \n",
        "      w = tf.Variable(initial_value=initial_w, name='W')\n",
        "\n",
        "      \"\"\"\n",
        "      Initializing the biases\n",
        "      All biases start from same value that is 0\n",
        "      Shape is no of neurons in layer\n",
        "      \"\"\"\n",
        "      initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
        "      # Calculation of the biases\n",
        "      b = tf.Variable(initial_value=initial_b, name='B')\n",
        "\n",
        "      \"\"\"\n",
        "      Input layer of next hidden layer\n",
        "      MatrixMultiplication\n",
        "      \"\"\"\n",
        "      layer_in = tf.matmul(input, w) + b\n",
        "\n",
        "      # Checking for the the last hidden layer to apply activation accordingly\n",
        "      if name=='out':\n",
        "        # Apply softmax for the last layer\n",
        "        layer_out = tf.nn.softmax(layer_in)\n",
        "      else:\n",
        "        # Apply relu for the remaining layers\n",
        "        layer_out = tf.nn.relu(layer_in)\n",
        "        \n",
        "      tf.summary.histogram('weights', w)\n",
        "      tf.summary.histogram('biases', b)\n",
        "        \n",
        "      return layer_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zOG84fyLDfqk"
      },
      "outputs": [],
      "source": [
        "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1], \n",
        "                      bias_dim=[n_hidden1], name='layer_1')\n",
        "\n",
        "layer_drop = tf.nn.dropout(layer_1, keep_prob=0.8, name='dropout_layer')\n",
        "\n",
        "layer_2 = setup_layer(layer_drop, weight_dim=[n_hidden1, n_hidden2], \n",
        "                      bias_dim=[n_hidden2], name='layer_2')\n",
        "\n",
        "output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES], \n",
        "                      bias_dim=[NR_CLASSES], name='out')\n",
        "\n",
        "model_name = f'{n_hidden1}-DO-{n_hidden2} LR{learning_rate} E{nr_epochs}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_PFW08fDfql"
      },
      "outputs": [],
      "source": [
        "# Folder for Tensorboard\n",
        "\n",
        "folder_name = f'{model_name} at {strftime(\"%H:%M\")}'\n",
        "directory = os.path.join(LOGGING_PATH, folder_name)\n",
        "\n",
        "try:\n",
        "    os.makedirs(directory)\n",
        "except OSError as exception:\n",
        "    print(exception.strerror)\n",
        "else:\n",
        "    print('Successfully created directories!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIMCqeHRDfqm"
      },
      "source": [
        "#### Defining Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3xT_otGQDfqm"
      },
      "outputs": [],
      "source": [
        "\n",
        "with tf.name_scope('loss_calc'):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Iw_otXDDfqm"
      },
      "source": [
        "#### Defining Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eQgDimuJDfqm"
      },
      "outputs": [],
      "source": [
        "with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    train_step = optimizer.minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "KbssGrXmDfqn"
      },
      "source": [
        "#### Accuracy Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eU7fq7cPDfqn"
      },
      "outputs": [],
      "source": [
        "with tf.name_scope('accuracy_calc'):\n",
        "    correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ706vezDfqn"
      },
      "outputs": [],
      "source": [
        "with tf.name_scope('performance'):\n",
        "    tf.summary.scalar('accuracy', accuracy)\n",
        "    tf.summary.scalar('cost', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWmU0OHxDfqo"
      },
      "source": [
        "#### Check Input Images in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5E_jh3IrDfqo"
      },
      "outputs": [],
      "source": [
        "with tf.name_scope('show_image'):\n",
        "    x_image = tf.reshape(X, [-1, 28, 28, 1])\n",
        "    tf.summary.image('image_input', x_image, max_outputs=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwF7sprZDfqp"
      },
      "source": [
        "# Run Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d0hMqqzzDfqp"
      },
      "outputs": [],
      "source": [
        "sess = tf.Session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGt3G7hgDfqp"
      },
      "source": [
        "#### Setup Filewriter and Merge Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yeHu4ioyDfqp"
      },
      "outputs": [],
      "source": [
        "merged_summary = tf.summary.merge_all()\n",
        "\n",
        "train_writer = tf.summary.FileWriter(directory + '/train')\n",
        "train_writer.add_graph(sess.graph)\n",
        "\n",
        "validation_writer = tf.summary.FileWriter(directory + '/validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR5FuTGTDfqq"
      },
      "source": [
        "#### Initialise all the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rgXHj8YHDfqq"
      },
      "outputs": [],
      "source": [
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2i9plCjDfqq"
      },
      "source": [
        "### Batching the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8jEPKcCbDfqq"
      },
      "outputs": [],
      "source": [
        "size_of_batch = 1000\n",
        "# size_of_batch = 500\n",
        "# size_of_batch = 2000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "01f-q-2ADfqr"
      },
      "outputs": [],
      "source": [
        "num_examples = y_training.shape[0]\n",
        "nr_iterations = int(num_examples/size_of_batch)\n",
        "\n",
        "index_in_epoch = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "RY2mwfntDfqr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this function is to go to the next batch\n"
      ],
      "metadata": {
        "id": "84kX0VBzrE4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jjSlo7xyDfqr"
      },
      "outputs": [],
      "source": [
        "def next_batch(batch_size, data, labels):\n",
        "    \n",
        "    global num_examples\n",
        "    global index_in_epoch\n",
        "    \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size\n",
        "    \n",
        "    if index_in_epoch > num_examples:\n",
        "        start = 0\n",
        "        index_in_epoch = batch_size\n",
        "    \n",
        "    end = index_in_epoch\n",
        "    \n",
        "    return data[start:end], labels[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3WIZQMkDfqr"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import array as arr\n",
        "accuracy_array = []"
      ],
      "metadata": {
        "id": "unW3WFQ28Cxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbPonrynDfqr"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "for epoch in range(nr_epochs):\n",
        "    \n",
        "    # ============= Training Dataset =========\n",
        "    for i in range(nr_iterations):\n",
        "        \n",
        "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_training, labels=y_training)\n",
        "        \n",
        "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
        "        \n",
        "        sess.run(train_step, feed_dict=feed_dictionary)\n",
        "        \n",
        "    \n",
        "    s, batch_accuracy = sess.run(fetches=[merged_summary, accuracy], feed_dict=feed_dictionary)\n",
        "        \n",
        "    train_writer.add_summary(s, epoch)\n",
        "    \n",
        "    print(f'Epoch {epoch} \\t| Training Accuracy = {batch_accuracy}')\n",
        "    \n",
        "    # ================== Validation ======================\n",
        "    \n",
        "    summary = sess.run(fetches=merged_summary, feed_dict={X:x_val, Y:y_val})\n",
        "    validation_writer.add_summary(summary, epoch)\n",
        "\n",
        "    accuracy_array.append(batch_accuracy)\n",
        "\n",
        "print('Done training!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy of the whole training model\n",
        "accuracy_of_model = np.mean(accuracy_array)\n",
        "print(\"Accuracy of model = {}%\".format(accuracy_of_model*100))"
      ],
      "metadata": {
        "id": "BuzDNR1g7Gxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VgLc013Dfqs"
      },
      "source": [
        "# Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnXagPr7Dfqs"
      },
      "outputs": [],
      "source": [
        "im = Image.open('/content/drive/MyDrive/MNIST/2.png')\n",
        "im"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = im.resize((28,28))"
      ],
      "metadata": {
        "id": "DFbl6T-KqGDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUFtz1GjDfqs"
      },
      "outputs": [],
      "source": [
        "bw = img.convert('L')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MBGKpPydDfqs"
      },
      "outputs": [],
      "source": [
        "img_array = np.invert(bw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9x0fO35Dfqt"
      },
      "outputs": [],
      "source": [
        "img_array.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KxpelVMgDfqt"
      },
      "outputs": [],
      "source": [
        "test_img = img_array.ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K5uwultDfqt"
      },
      "outputs": [],
      "source": [
        "test_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_array"
      ],
      "metadata": {
        "id": "E0JPM3AO6gDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "57f4ytRPDfqu"
      },
      "outputs": [],
      "source": [
        "prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGPwp9akDfqu"
      },
      "outputs": [],
      "source": [
        "print(f'Prediction for test image is {prediction}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJbjgYIrDfqu"
      },
      "source": [
        "# **Testing and Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0os9IgpDfqu"
      },
      "outputs": [],
      "source": [
        "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_testing, Y:y_testing})\n",
        "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test_image(Img_url):\n",
        "  im = Image.open(Img_url)\n",
        "  img = im.resize((28, 28))\n",
        "  bw = img.convert('L')\n",
        "  img_array = np.invert(bw)\n",
        "  test_img = img_array.ravel()\n",
        "  prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})\n",
        "  print(f'Prediction for test image is {prediction}')"
      ],
      "metadata": {
        "id": "RisXB8zbvXOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_test_image1(Img_url):\n",
        "  im = Image.open(Img_url)\n",
        "  img = im.resize((28, 28))\n",
        "  bw = img.convert('L')\n",
        "  img_array = np.invert(bw)\n",
        "  test_img = img_array.ravel()\n",
        "  prediction = sess.run(fetches=tf.argmax(output, axis=1), feed_dict={X:[test_img]})\n",
        "  print(f'Prediction for test image is {prediction}')"
      ],
      "metadata": {
        "id": "5rNzJR107xui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction 1"
      ],
      "metadata": {
        "id": "kMJw1_vvwvnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/1.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/1.png');\n"
      ],
      "metadata": {
        "id": "OUdm3cq9wzC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction 2"
      ],
      "metadata": {
        "id": "cnfY3aAHkrp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/2.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/2.png');"
      ],
      "metadata": {
        "id": "6iModX5yyIV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction 3"
      ],
      "metadata": {
        "id": "l2YcsHcZyeSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/3.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/3.png');"
      ],
      "metadata": {
        "id": "n1Q3-Xqbyixt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction 4"
      ],
      "metadata": {
        "id": "49YEENRGyf4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/4.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/4.png');"
      ],
      "metadata": {
        "id": "WuGRs9lWysB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/ii_4.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/ii_4.png');"
      ],
      "metadata": {
        "id": "YzGZVwZtythE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/8.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/8.png');"
      ],
      "metadata": {
        "id": "S_4Lt6TB0uqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/7777.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/7777.png');"
      ],
      "metadata": {
        "id": "82nMWh5S6gFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/22222.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/22222.png');"
      ],
      "metadata": {
        "id": "8mYnFVTT6f7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/drive/MyDrive/MNIST/555555.png')\n",
        "display(img)\n",
        "predict_test_image('/content/drive/MyDrive/MNIST/555555.png');"
      ],
      "metadata": {
        "id": "sMnVgNtW6fzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Webpage"
      ],
      "metadata": {
        "id": "_ZUwF_TtqZzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = test_accuracy*100\n",
        "model_accuracy = round(temp,2)\n",
        "df = px.data.tips()# Build App\n",
        "app = JupyterDash(__name__)\n",
        "app.layout = html.Div([\n",
        "    html.H1(\"ML SEMESTER PROJECT\"),\n",
        "    html.H1(\"DIGIT RECOGNITION\"),\n",
        "    html.H2(\"Model Accuracy: {}%\".format(model_accuracy)),\n",
        "    html.H2(\"Img:\"),\n",
        "    #html.Img(src = \"https://drive.google.com/uc?export=view&id=1UcMUe3ifP9ijRuQtHWavWsvVnPteRm6w\"), #Test image 1\n",
        "    html.Img(src = \"https://drive.google.com/uc?export=view&id=1_L1CCgQ-x1c5FCeExEPmXoXmBpnCUy_W\"), #Test image 2\n",
        "    \n",
        "    html.H2(\"Prediction: {}\".format(prediction)),\n",
        "])\n",
        "\n",
        "# app.run_server(mode='external')\n",
        "app.run_server(host=\"127.0.0.1\", port=\"8000\")"
      ],
      "metadata": {
        "id": "_MaqRi69qZTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WKkGP--LwMXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "iZC7o_UKDfqv"
      },
      "source": [
        "# Reset for the Next Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7JkuDdV3Dfqv"
      },
      "outputs": [],
      "source": [
        "train_writer.close()\n",
        "validation_writer.close()\n",
        "sess.close()\n",
        "tf.reset_default_graph()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Semester Project Machine Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}